import pandas as pd
from pandas.api.types import is_numeric_dtype
import numpy as np
from hydromt.data_catalog import DataCatalog
import logging


class Vulnerability:
    def __init__(self, data_catalog: DataCatalog):
        self.data_catalog = data_catalog

    def get_vulnerability_source(self, vulnerability_source: str):
        # Load the vulnerability functions from the source
        # TODO: add some checks to validate the df_source
        return self.data_catalog.get_dataframe(vulnerability_source)

    def get_vulnerability_identifiers_and_linking_source(
        self, vulnerability_identifiers_and_linking_source: str
    ):
        # USER INPUT, read vulnerability identifiers and linking csv generated via gui or manual input.
        # TODO: add some checks to validate the df_identifiers_linking
        return pd.read_csv(vulnerability_identifiers_and_linking_source)

    def get_vulnerability_functions_from_one_file(
        self,
        df_source: pd.DataFrame,
        df_identifiers_linking: pd.DataFrame,
        unit: str,
    ):

        # Identify the unique combinations of values from the identifiers and linking data frame that will be used to select subsets of values from the source data frame.
        # unique_combinations = df_identifiers_linking.groupby(['ID', 'Occupancy', 'Source', 'Description']).nunique().reset_index()

        identifier_columns = self.get_identifier_names(df_identifiers_linking)
        df_source = self.add_full_identifier_column(df_source, identifier_columns)
        df_identifiers_linking = self.add_full_identifier_column(
            df_identifiers_linking, identifier_columns
        )

        combined_df = self.link_vfs_from_source(df_source, df_identifiers_linking)

        # Delete the column used to link the dataframes
        del combined_df["full_identifier"]

        # Get the columns with damage fractions
        fraction_cols = self.get_hazard_value_columns(combined_df)

        # Get the hazard values from the columns
        hazard_values = self.get_hazard_values_from_columns(fraction_cols)

        # Get vulnerability factors
        vf_values_only = combined_df[fraction_cols].values

        # Check whether the vulnerability factors are fractions or percentages and
        # convert into fractions if they are percentages
        if vf_values_only.max() > 1:
            vf_values_only = vf_values_only / 100

        vf_names = df_identifiers_linking["Name"].values
        v_dataframe = self.combine_vulnerability_functions(
            hazard_values, vf_values_only, vf_names, unit
        )

        # Export the dataframe to a csv.
        v_dataframe.to_csv(
            "vulnerability_test_file_output.csv", index=False, header=False
        )

    @staticmethod
    def get_identifier_names(
        df: pd.DataFrame, to_remove: list = ["Name", "Link"]
    ) -> list:
        """_summary_

        Parameters
        ----------
        df : pd.DataFrame
            _description_
        to_remove : list
            _description_

        Returns
        -------
        list
            _description_
        """
        # Check which columns are used as identifiers. These are all columns beside the 'to_remove' columns
        _identifier_columns = list(df.columns)
        for col in to_remove:
            _identifier_columns.remove(col)
        return _identifier_columns

    @staticmethod
    def add_full_identifier_column(
        df: pd.DataFrame, identifier_columns: list
    ) -> pd.DataFrame:
        # Create temporary columns of the identifier columns to be able to filter them
        # with flexible user input
        for c in identifier_columns:
            if is_numeric_dtype(df[c]):
                df[c] = df[c].astype(int).astype(str)

        df["full_identifier"] = df[identifier_columns].apply(
            lambda x: x.str.cat(sep=""), axis=1
        )
        df["full_identifier"] = df["full_identifier"].str.replace(" ", "")
        return df

    @staticmethod
    def link_vfs_from_source(
        vf_source: pd.DataFrame, vf_identifiers_linking: pd.DataFrame
    ) -> pd.DataFrame:
        # Initialize an empty list to hold the subsets
        subsets = []

        # Loop over the unique combinations of values
        for i in range(len(vf_identifiers_linking)):
            # Use the unique combination of values to select the corresponding subset of values
            # from the first data frame using boolean indexing
            subset = vf_source.loc[
                vf_source["full_identifier"]
                == vf_identifiers_linking.loc[i, "full_identifier"]
            ]

            # Check if the subset is empty
            if subset.empty:
                logging.warn(
                    f"No vulnerability curves found for unique combination {vf_identifiers_linking.loc[i]}"
                )

            # Append the subset of values to the list of subsets
            subsets.append(subset)

        # Concatenate all of the necessary vulnerability curves info into a single data frame using pd.concat()
        return pd.concat(subsets, ignore_index=True)

    @staticmethod
    def get_hazard_value_columns(df: pd.DataFrame):
        # Get the columns with damage fractions
        def has_numbers(inputString):
            return any(char.isdigit() for char in inputString)

        return [c for c in df.columns if has_numbers(c)]

    @staticmethod
    def get_hazard_values_from_columns(columns: list) -> list:
        # Get the hazard values from the column names
        list_hazard_values = list(
            map(
                lambda sub: float("".join([ele for ele in sub if ele.isnumeric()])),
                columns,
            )
        )
        if list_hazard_values[0] != 0:
            # The hazard values start with negative values
            list_hazard_values[: list_hazard_values.index(0)] = [
                -x for x in list_hazard_values[: list_hazard_values.index(0)]
            ]
        return list_hazard_values

    @staticmethod
    def combine_vulnerability_functions(
        list_hazard_values: list, vf_values_only: np.array, vf_names: list, unit: str
    ) -> pd.DataFrame:
        """_summary_

        Parameters
        ----------
        list_hazard_values : list
            _description_
        vf_values_only : np.array
            _description_
        vf_names : list
            _description_
        unit : str
            _description_

        Returns
        -------
        pd.DataFrame
            _description_
        """
        vf_water_depths_numbers = np.array(list_hazard_values)
        vf_water_depths = np.array(vf_water_depths_numbers.reshape(-1, 1))
        vf_raw = np.hstack([vf_water_depths, vf_values_only.T])

        vf_names_header = np.append("water depth", vf_names)
        top_header_array = np.full(
            (1, vf_names_header.shape[0]), fill_value="", dtype="<U100"
        )
        top_header_array[0, 0] = f"#UNIT={unit}"

        vf_names_header = vf_names_header.reshape(top_header_array.shape)

        vf_fiat_format = np.concatenate([top_header_array, vf_names_header, vf_raw])

        # Create a dataframe out of the previous array.
        return pd.DataFrame(vf_fiat_format)
